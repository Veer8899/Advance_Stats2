{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9673be-c66b-46cf-b3b1-34c06c650dec",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831e886-d82e-4d60-89cd-f9108e996d3b",
   "metadata": {},
   "source": [
    "### Probability Mass Function (PMF):\n",
    "#### The PMF is used for discrete random variables, which means the possible values the random variable can take are countable and distinct. \n",
    "#### Example: The roll of a fair six-sided dice.\n",
    "#### Let's consider the roll of a fair six-sided die. The random variable X represents the outcome of the die roll. The possible values of X are 1, 2, 3, 4, 5, and 6, each with equal probability 1/6.\n",
    "\n",
    "#### The PMF for this example is as follows:\n",
    "##### P(X = 1) = 1/6\n",
    "##### P(X = 2) = 1/6\n",
    "##### P(X = 3) = 1/6\n",
    "##### P(X = 4) = 1/6\n",
    "##### P(X = 5) = 1/6\n",
    "##### P(X = 6) = 1/6\n",
    "\n",
    "### Probability Density Function (PDF): \n",
    "#### The PDF, on the other hand, is used for continuous random variables, where the possible values of the random variable form an interval and are not countable individually.\n",
    "#### Example:  The height of people in a population\n",
    "#### Let's consider a continuous random variable Y representing the height of people in a population, assuming it follows a normal distribution. The PDF for the height can be described by a bell-shaped curve.\n",
    "\n",
    "#### In this case, the PDF might look something like this:\n",
    "\n",
    "#### f(Y = y) = (1 / (√(2π)σ)) * e^(-(y - μ)^2 / (2σ^2))\n",
    "\n",
    "#### where μ is the mean and σ is the standard deviation of the height distribution.\n",
    "\n",
    "#### The probability of a person's height falling within a certain range can be calculated by integrating the PDF over that range, as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf38a4-0880-4bca-be0a-c81de88e5847",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99520914-c74d-4a5a-9a53-f9b93a806310",
   "metadata": {},
   "source": [
    "#### The Cumulative Distribution Function (CDF) is a function used to describe the cumulative probability distribution of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabea85-a3ee-42bf-9d29-afda589c5a13",
   "metadata": {},
   "source": [
    "### Example of CDF:\n",
    "#### Let's consider a discrete random variable X representing the outcome of a coin toss. The possible values of X are {H, T}, where H stands for heads and T stands for tails. Since it's a fair coin, the probability of getting heads or tails is both 0.5 (or 50%).\n",
    "\n",
    "#### The CDF for this example is as follows:\n",
    "##### F(X = H) = P(X ≤ H) = P(X = H) = 0.5\n",
    "##### F(X = T) = P(X ≤ T) = P(X = H) + P(X = T) = 0.5 + 0.5 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28bae1-6739-4f1e-a59d-87ccc27d0281",
   "metadata": {},
   "source": [
    "### The CDF is used for several reasons in probability and statistics:\n",
    "#### Calculating probabilities\n",
    "#### Quantile calculation\n",
    "#### Comparison of distributions\n",
    "#### Hypothesis testing\n",
    "#### Generating random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0683e-adf6-4898-b85a-483d14e0d617",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316738e-c6c2-4cba-9bfd-3385f977038e",
   "metadata": {},
   "source": [
    "### Some examples of situations where the normal distribution might be used as a model :\n",
    "#### Heights and weights: When measuring the heights and weights of a large population, the distribution of these values tends to follow a bell-shaped curve, which can be well approximated by a normal distribution.\n",
    "\n",
    "#### Test scores: In standardized tests, the scores of a large group of test-takers often follow a normal distribution. This distribution helps in setting percentile rankings and evaluating performance.\n",
    "\n",
    "#### Errors in measurements: In many scientific experiments and real-world data collection processes, errors can occur during measurement. These errors are often assumed to follow a normal distribution, making it convenient to apply statistical methods.\n",
    "\n",
    "#### IQ scores: Intelligence quotient (IQ) scores of a large population typically follow a normal distribution, with the majority of people clustered around the average score.\n",
    "\n",
    "#### Stock market returns: Daily stock market returns are often assumed to be normally distributed, although in reality, they may exhibit more complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009e536-442a-47ca-8759-908beb14c9ca",
   "metadata": {},
   "source": [
    "### The parameters of the normal distribution relate to the shape of the distribution:\n",
    "\n",
    "#### The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution and determines its location on the x-axis, while the standard deviation controls the spread or dispersion of the data points around the mean on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38b34f-f81e-4c4b-bf12-2374ef0a42c8",
   "metadata": {},
   "source": [
    "#### Mean (μ): The mean is the expected value or average of the data. It defines the center of the normal distribution and is the value around which the data points are symmetrically distributed. When you change the mean, the whole distribution shifts horizontally left or right.\n",
    "\n",
    "#### Standard Deviation (σ): The standard deviation is a measure of the spread or dispersion of the data points from the mean. A larger standard deviation means the data points are more spread out, resulting in a wider, flatter curve. Conversely, a smaller standard deviation results in a narrower, taller curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fdc51-47e7-4427-9c60-a92bdce638df",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82dfc52-73b9-4ae6-b338-88f417f5926c",
   "metadata": {},
   "source": [
    "### The importance of Normal Distribution:\n",
    "#### >The normal distribution is a common pattern found in various real-world situations.\n",
    "#### >Its bell-shaped curve is easy to interpret and visualize.\n",
    "#### >The Central Limit Theorem allows approximating sample means from any population, even when individual data points are not normally distributed.\n",
    "#### >It underpins many statistical tests, enabling hypothesis testing and parameter estimation.\n",
    "#### >It serves as a basis for estimating parameters of other distributions, making educated guesses about unknown data distributions.\n",
    "#### >It helps build predictive models that closely match real-world phenomena.\n",
    "#### >It facilitates standardizing data for easy comparison and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afa78c-21fc-4b4e-919b-36a931c8b884",
   "metadata": {},
   "source": [
    "### Real-Life Examples of Normal Distribution:\n",
    "#### Human Heights: The heights of adults from a large population often follow a normal distribution. The majority of people are clustered around the average height, with fewer individuals at the extreme ends (very tall or very short).\n",
    "\n",
    "#### Exam Scores: In educational testing, the scores of a large group of students on a well-designed exam tend to approximate a normal distribution. Most students score around the average, with fewer students scoring at the highest and lowest ends.\n",
    "\n",
    "#### IQ Scores: Intelligence Quotient (IQ) scores across a population are usually modeled by a normal distribution. The majority of individuals have an average IQ, while fewer people fall into the high and low IQ ranges.\n",
    "\n",
    "#### Body Mass Index (BMI): The Body Mass Index, a measure of body fat based on height and weight, is often distributed normally within a population. Most individuals have a BMI close to the average, with fewer people at the extreme ends.\n",
    "\n",
    "#### Errors in Measurement: Errors that occur during measurement, such as in scientific experiments, tend to follow a normal distribution. The magnitude of errors is typically distributed around the true value with smaller errors being more common and larger errors being rarer.\n",
    "\n",
    "#### Reaction Times: In cognitive psychology, the distribution of reaction times for certain tasks is often modeled by a normal distribution. The majority of participants respond close to the average reaction time, with fewer participants having very fast or very slow reaction times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd6396-ca25-451a-867d-3c4ed59544f7",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d0fc4-00fb-4674-9b3a-aa04cff79a13",
   "metadata": {},
   "source": [
    "#### The Bernoulli distribution is a discrete probability distribution that models a single binary outcome, where an experiment results in either success (usually denoted as \"1\") with probability \"p\" or failure (denoted as \"0\") with probability \"q\" (where q = 1 - p). In other words, it represents a random experiment with two possible outcomes, often referred to as a \"success\" or \"failure.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ed63b-949c-410f-86d0-f579f964c77b",
   "metadata": {},
   "source": [
    "### Example of Bernoulli Distribution:\n",
    "\n",
    "#### Consider the experiment of flipping a fair coin. The outcome of each coin flip can be represented as a Bernoulli random variable. Let's define \"1\" as getting heads and \"0\" as getting tails. In this case, the probability of success (getting heads) is p = 0.5, and the probability of failure (getting tails) is q = 1 - p = 0.5. Each coin flip is independent of the others, making it a suitable scenario for the Bernoulli distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937267d-77b7-4456-ae71-5084ed03c908",
   "metadata": {},
   "source": [
    "### Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "#### >Number of Trials:\n",
    "\n",
    "##### Bernoulli Distribution: Represents a single trial with two possible outcomes (success or failure).\n",
    "##### Binomial Distribution: Represents the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "#### >Number of Outcomes:\n",
    "\n",
    "##### Bernoulli Distribution: Has two possible outcomes (0 or 1) with associated probabilities (p and q).\n",
    "##### Binomial Distribution: Has a range of possible outcomes, representing the number of successes in a fixed number of trials, typically denoted as \"k.\"\n",
    "\n",
    "#### >Number of Parameters:\n",
    "\n",
    "##### Bernoulli Distribution: Requires a single parameter, \"p,\" which is the probability of success in a single trial.\n",
    "##### Binomial Distribution: Requires two parameters, \"n\" (the number of trials) and \"p\" (the probability of success in a single trial).\n",
    "\n",
    "#### >Usage:\n",
    "\n",
    "##### Bernoulli Distribution: Used for modeling a single binary outcome or a simple \"yes/no\" event.\n",
    "##### Binomial Distribution: Used when we want to find the probability of a specific number of successes (k) in a fixed number of independent trials.\n",
    "\n",
    "#### >Formula:\n",
    "\n",
    "##### Bernoulli Distribution: P(X = x) = p^x * q^(1-x), where x = 0 or 1.\n",
    "##### Binomial Distribution: P(X = k) = C(n, k) * p^k * q^(n-k), where k = 0, 1, 2, ..., n, and C(n, k) is the binomial coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd38389-c313-41f2-955f-a24ea9b0db68",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88735a-1239-4d5a-9db2-a7c441471049",
   "metadata": {},
   "source": [
    "### The formula for calculating the z-score is:\n",
    "\n",
    "z= x−μ/σ\n",
    "\n",
    "where:\n",
    "\n",
    "x=60\n",
    "μ=50\n",
    "σ=10\n",
    "\n",
    "z = 60-50/10 = 10/10 = 1\n",
    "\n",
    "#### Now, we need to find the probability of the z-score being greater than 1. We can use a standard normal distribution table or a statistical calculator to find this probability. For a z-score of 1, the probability is approximately 0.8413.\n",
    "\n",
    "#### So, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.8413 or 84.13%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbb9d9-34d2-4323-8835-43372a5af381",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1dec9-b4fe-4bfe-b349-ad1092dbb3f8",
   "metadata": {},
   "source": [
    "#### The uniform distribution is a type of probability distribution where every possible outcome within a given range is equally likely. It is characterized by a constant probability density function (PDF) over the entire range. In other words, all values within the specified interval have the same chance of occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91032c17-c63b-484c-b5b7-7657e96a8e4d",
   "metadata": {},
   "source": [
    "### Example of Uniform Distribution:\n",
    "\n",
    "#### Let's consider an example of rolling a fair six-sided die. In this case, the possible outcomes are the numbers 1 to 6, and each outcome has an equal chance of occurring. This is an example of a discrete uniform distribution because the outcomes are distinct and countable.\n",
    "\n",
    "### For a fair six-sided die, the probability of each outcome is:\n",
    "\n",
    "#### P(X = 1) = P(X = 2) = P(X = 3) = P(X = 4) = P(X = 5) = P(X = 6) = 1/6\n",
    "#### Graphically, the probability density function (PDF) of a discrete uniform distribution looks like a flat horizontal line at a constant height over the range of possible values (1 to 6 in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfed206-8bd8-4d9f-a437-5e09fc2df665",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8f16c-6768-4344-b200-3c01f87dec14",
   "metadata": {},
   "source": [
    "#### The z-score, also known as the standard score, is a statistical measure that quantifies how many standard deviations a data point is away from the mean of a dataset. It allows us to standardize and compare data points from different distributions on a common scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc79321-6e63-4070-ae55-9c688ca78360",
   "metadata": {},
   "source": [
    "### Importance of the z-score: \n",
    "\n",
    "#### Standardization: The z-score standardizes data, transforming it into a common unit of measurement. This allows us to compare values from different datasets and different scales.\n",
    "\n",
    "#### Outlier Detection: Z-scores help identify outliers in a dataset. Data points with z-scores significantly higher or lower than the mean may indicate unusual observations or data errors.\n",
    "\n",
    "#### Probability Estimation: Z-scores are crucial in calculating probabilities under the assumption of a normal distribution. They are used to find the area under the normal curve and determine the likelihood of observing a specific value or range of values.\n",
    "\n",
    "#### Data Transformation: By converting data into z-scores, we can perform transformations that make the data more suitable for analysis or modeling, such as data normalization.\n",
    "\n",
    "#### Quality Control: In quality control and process monitoring, z-scores are used to assess whether a sample is within acceptable bounds or if it deviates significantly from the expected values.\n",
    "\n",
    "#### Comparing Different Distributions: When dealing with multiple datasets, the z-score enables a direct comparison of values, even if the datasets have different means and standard deviations.\n",
    "\n",
    "#### Standard Normal Distribution: In the case of a normal distribution, z-scores are directly related to percentiles, making it easy to determine the relative position of a data point in the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad36bfc-fca2-4f2c-95ec-e24fb41718ed",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd97aa-0916-4a1f-8f13-3f39ee9f6c28",
   "metadata": {},
   "source": [
    "#### The Central Limit Theorem (CLT) is a fundamental concept in statistics. It states that, regardless of the shape of the original population's distribution, the sampling distribution of the sample means approaches a normal distribution as the sample size increases. \n",
    "\n",
    "### Significance of the Central Limit Theorem:\n",
    "\n",
    "#### Inference and Hypothesis Testing: The Central Limit Theorem allows us to make inferences about population parameters based on sample statistics. When the population distribution is unknown or not normally distributed, we can still rely on the normal distribution assumptions for sample means. This is the basis for many hypothesis tests and confidence interval calculations.\n",
    "\n",
    "#### Population Estimation: The Central Limit Theorem is particularly useful when the population is large or when it is challenging to access the entire population. By taking random samples and calculating sample means, we can make accurate estimates about the population mean.\n",
    "\n",
    "#### Data Analysis: The CLT simplifies data analysis by providing a standardized way to work with sample means. It allows us to use familiar statistical techniques that assume normality, even if the population data does not follow a normal distribution.\n",
    "\n",
    "#### Stability of Sample Means: As the sample size increases, the sampling distribution of the sample means becomes more stable and closer to a normal distribution. This means that larger samples yield more reliable estimates of the population mean.\n",
    "\n",
    "#### Random Sampling Benefits: The Central Limit Theorem justifies the use of random sampling in surveys and experiments. It tells us that as long as we take sufficiently large random samples, the distribution of sample means will converge to normality.\n",
    "\n",
    "#### Decision Making: Many statistical methods and models assume normality of the data. The CLT allows us to apply these methods in various real-world scenarios, even if the data itself is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898e368-3e51-4ec5-a49d-150d06942e44",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52060e83-1206-4af7-8743-a0fd0dd91090",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem (CLT) relies on several key assumptions to hold true. These assumptions are:\n",
    "\n",
    "#### Random Sampling: The samples should be randomly selected from the population. This means that every individual in the population should have an equal chance of being included in the sample.\n",
    "\n",
    "#### Independence: The observations within each sample should be independent of each other. In other words, the value of one observation should not influence the value of another observation within the same sample.\n",
    "\n",
    "#### Sample Size: The sample size should be sufficiently large. While there is no strict rule for what constitutes a \"large\" sample size, in general, a sample size greater than 30 is considered large enough for the CLT to apply.\n",
    "\n",
    "#### Finite Variance: The population from which the samples are drawn should have a finite variance. This means that the variability within the population should not be infinite.\n",
    "\n",
    "#### Identical Distribution: Each sample should come from the same population, and the population should have the same mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43794b89-32b0-459e-b77c-b14d4027adb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
